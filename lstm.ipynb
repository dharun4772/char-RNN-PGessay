{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 3240634\n"
     ]
    }
   ],
   "source": [
    "with open(\"cleaned_pgessay.txt\",\"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "text = normalize_text(text)\n",
    "\n",
    "\n",
    "#Creating vocab\n",
    "temp_text = text.replace(\"<sot>\",\"\").replace(\"<eot>\",\"\")\n",
    "vocab = set(['<sot>','<eot>'])\n",
    "for ch in temp_text:\n",
    "    vocab.add(ch)\n",
    "\n",
    "\n",
    "print(len(vocab), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chidx = {ch:idx for idx, ch in enumerate(vocab)}\n",
    "idxch = {idx:ch for ch, idx in chidx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_x = []\n",
    "idx=0\n",
    "while idx<len(text):\n",
    "    ch = text[idx]\n",
    "    if text[idx:min(idx+5,len(text))] in vocab:\n",
    "        inputs_x.append(text[idx:min(idx+5,len(text))])\n",
    "        idx+=5\n",
    "    elif text[idx:min(idx+2,len(text))] in vocab:\n",
    "        inputs_x.append(text[idx:min(idx+2,len(text))])\n",
    "        idx+=2\n",
    "    else:\n",
    "        inputs_x.append(ch)\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(inputs_x) - seq_length):\n",
    "    X.append(inputs_x[i:i+seq_length]) \n",
    "    y.append(inputs_x[i+seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "sequnce_length = 25\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length))\n",
    "model.add(tf.keras.layers.LSTM(units = 100))\n",
    "model.add(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[chidx[ele] for ele in x] for x in X]\n",
    "y = [chidx[ele] for ele in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 34ms/step - loss: 1.9415 - val_loss: 1.5286\n",
      "Epoch 2/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 29ms/step - loss: 1.4978 - val_loss: 1.4495\n",
      "Epoch 3/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1215s\u001b[0m 30ms/step - loss: 1.4363 - val_loss: 1.4213\n",
      "Epoch 4/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1281s\u001b[0m 31ms/step - loss: 1.4073 - val_loss: 1.4039\n",
      "Epoch 5/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1402s\u001b[0m 35ms/step - loss: 1.3914 - val_loss: 1.3929\n",
      "Epoch 6/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2403s\u001b[0m 59ms/step - loss: 1.3787 - val_loss: 1.3816\n",
      "Epoch 7/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1403s\u001b[0m 33ms/step - loss: 1.3689 - val_loss: 1.3754\n",
      "Epoch 8/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 28ms/step - loss: 1.3646 - val_loss: 1.3711\n",
      "Epoch 9/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1208s\u001b[0m 30ms/step - loss: 1.3580 - val_loss: 1.3683\n",
      "Epoch 10/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1296s\u001b[0m 32ms/step - loss: 1.3513 - val_loss: 1.3657\n",
      "Epoch 11/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 33ms/step - loss: 1.3489 - val_loss: 1.3636\n",
      "Epoch 12/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1095s\u001b[0m 27ms/step - loss: 1.3441 - val_loss: 1.3630\n",
      "Epoch 13/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1184s\u001b[0m 29ms/step - loss: 1.3433 - val_loss: 1.3577\n",
      "Epoch 14/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3198s\u001b[0m 78ms/step - loss: 1.3406 - val_loss: 1.3616\n",
      "Epoch 15/15\n",
      "\u001b[1m40485/40485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2917s\u001b[0m 72ms/step - loss: 1.3396 - val_loss: 1.3557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1669d82bf90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=15,\n",
    "    batch_size=64, \n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, n_chars_to_generate=100):\n",
    "    generated_text = seed_text\n",
    "    \n",
    "    for _ in range(n_chars_to_generate):\n",
    "        token_list = [chidx.get(char, 0) for char in generated_text[-seq_length:]]\n",
    "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
    "\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        # predicted_index = np.argmax(predicted_probs)\n",
    "        # mixer = {ele:predicted_probs[0][idx] for idx,ele in enumerate(vocab)}\n",
    "        # print({k: v for k, v in sorted(mixer.items(), key=lambda item: item[1], reverse=True)})\n",
    "        random_sample = np.random.choice(range(vocab_size), p=predicted_probs.ravel())\n",
    "        predicted_char = idxch.get(random_sample, '')\n",
    "        generated_text += predicted_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"her fame.you start a startup.with the optimising this professional them that lisp current when they're makin\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"her fame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
